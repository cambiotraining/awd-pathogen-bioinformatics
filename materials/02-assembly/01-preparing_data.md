---
title: Preparing data
---

::: {.callout-tip}
#### Learning Objectives

- Recognise the importance of organising your files and folders when starting a bioinformatic analysis.
- Investigate the content of the raw sequencing FASTQ files.
- Download available public reference genomes from public databases.
:::


## Setting up Directories and Preparing files

For convenience and reproducibility of any bioinformatic analysis, it is good practice to set up several directories before starting your analysis. 
It is also convenient to download any required files from public databases, such as reference genomes. 

You can do this from your file browser or using the command line. 
We recommend starting with an empty directory that will be used to store all the data and scripts used during the analysis. 
Here are some recommended directories that you should create inside it: 

- `data` - for storing raw data (fastq files)
- `scripts` - for storing all scripts for running analysis at different stages
- `results` - for storing results of the pipeline
- `reports` - for storing reports
- `resources` - for storing files from public repositories, such as reference genomes and other databases we will require during our analysis.

:::{.callout-note}
#### Note for workshop attendees

If you're attending one of our live workshops, we've already prepared the data for you to save time in downloading and preparing the files. 
However, you can read this section to understand where the data came from.
:::

From the command line, you can create directories using the command `mkdir` followed by the directory name. 
In our example, we will be working from our Documents folder, which is located in `~/Documents/` (note: remember that `~` is a shortcut to your home directory). 

We start by moving into that directory: 

```bash
cd ~/Documents
```

And then we create a folder for our project. 
We call this folder `awd_workshop`:

```bash
mkdir awd_workshop
```

We can then move into that folder using `cd` again:

```bash
cd awd_workshop
```


## Sequencing files

Our bioinformatics analysis will start by first looking at the FASTQ files generated by the basecalling software called _Guppy_. 
This software converts the Nanopore electrical signal to sequence calls and stores the results in a directory named **fastq_pass**, which contains a subdirectory for each sample barcode used. 

We can use the command `ls`` to view the raw data:

```bash
ls data/fastq_pass
```

```
barcode01  barcode02  barcode05  barcode06  barcode09
```

In our example, we had 5 samples with the barcodes shown (yours might look different). 

If you wanted to quickly look at how many reads you have in each file, you could use some command line tricks: 

- first combine all the FASTQ files from a barcode using `zcat` (we use the `z*` variant of the `cat` command because our files are compressed)
- pipe the output to the `wc -l` to count the number of lines in the combined files
- then divide that number by 4, because each sequence is represented in 4 lines in FASTQ files

For example, for `barcode01` we could do: 

```bash
zcat data/fastq_pass/barcode01/*.fastq.gz | wc -l
```

```
394384
```

If we divide that value by 4, we can determine that we have 98,596 reads in this sample. 


:::{.callout-note collapse=true}
#### Advanced: automatically determining read number across barcodes

The following code is more advanced, but it allows us to determine how many reads we have in each barcode without having to type each command individually. 
Instead, we use a _for loop_ to automatically perform our task of counting reads for each barcode.

If you feel confortable using the command line, you can try it out.

```bash
for barcode in data/fastq_pass/*
do
  # count total lines in all files within a barcode folder
  nlines=$(zcat $barcode/* | wc -l)
  
  # divide the value by 4 (each sequence is represented in 4 lines in FASTQ files)
  nreads=$(( $nlines / 4 ))
  
  # print the result
  echo "Reads in ${barcode}: ${nreads}"
done
```

```
Reads in data/fastq_pass/barcode01: 98596
Reads in data/fastq_pass/barcode02: 113252
Reads in data/fastq_pass/barcode03: 95725
Reads in data/fastq_pass/barcode04: 190186
Reads in data/fastq_pass/barcode05: 87929
Reads in data/fastq_pass/barcode06: 112216
Reads in data/fastq_pass/barcode07: 143620
Reads in data/fastq_pass/barcode08: 1372705
Reads in data/fastq_pass/barcode09: 163440
```

To learn more about _for loops_ see our [Unix course materials](https://cambiotraining.github.io/unix-shell/materials/02-programming/03-loops.html). 
:::


## Metadata

Having metadata (data about our raw FASTQ files) is important in order to have a clear understanding on how the samples and raw data were generated. 
Information like sample names, date of collection, the location where they were collected, sequencing platform used, protocol, etc. are all important for downstream analysis and to further our interpretation of the results and reporting.

Some of this information can be stored in a CSV file, created with a spreadsheet software. 
Here is an example for the samples we are using in these materials: 

TODO: add table with example metadata


## Public genomes

In our example, we are working with cultured samples of the _Vibrio cholerae_ bacteria, the causative pathogen of the cholera disease, of which AWD is a major symptom. 
Therefore, we will download a reference genome for this pathogen, which will help with our downstream analysis of our data. 

There are many complete genomes available for _V. cholerae_, which can be [downloaded from the NCBI public database](https://www.ncbi.nlm.nih.gov/datasets/genome/?taxon=666&annotated_only=true&refseq_annotation=true&typical_only=true).
The first full genome was [published in 2000](https://doi.org/10.1038/35020000) from the clinical isolate N16961, which belongs to serogroup O1, serotype Inaba, biotype El Tor. 
This is a typical strain from the current pandemic, often referred to as '7PET' (7th pandemic El Tor).

We could use the N16961 isolate as our reference genome, however we opted by using a more recent strain collected in 2019, as it is more likely to be closely-related to our isolates and therefore more suited to help with our genome assembly later on. 
Our chosen reference strain is named [CNRVC190243](https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_937000105.1/) and described as: "O1 strain of the wave 3 of the seventh pandemic El-Tor (7PET) lineage, sublineage T13". 

The [_Vibriowatch_ website](https://genomic-surveillance-for-vibrio-cholerae-using-vibriowatch.readthedocs.io/en/latest/mlst.html#compare-your-isolate-to-vibriowatch-s-reference-genomes) (which we will detail more about in a later chapter) also provides a set of 17 'reference genomes', 14 of which belong to the current pandemic (7PET) lineages. 
Their reference genomes are named as 'Wi_Tj' where 'W' stands for a **Wave** and 'i' is its number, and 'T' stands for **Transmission** event and 'j' its number. 
For instance, a W1_T1 reference strain means "wave one transmission one". 

Our reference genome of choice is a strain related to 'W3_T13' and has been associated with a cholera outbreak in Yemen from 2019.
This sample is available from the following link: https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_937000105.1/.

From the link above you can see information about the genome assembly of this strain, as shown below. 
The assembly is complete with 99.69% of the genome recovered.

![](images/ref_genome_download_page.png)

In that same page, you will see a "Download" button. 
When you click that button, the pop-up window will be displayed as illustrated in the image below.

![](images/ref_genome_download_pop_up_button.png)

The reference genome sequence can be selected by ticking 'Genome sequences (FASTA)' and the gene annotation by ticking 'Annotation features (GFF)' formats. 
You can chang the name of the file that will be downloaded and finally, click the 'Download' button to download the reference genome assembly.

The downloaded file is compressed as a Zip file, which you can uncompress and copy the files to your project folder. 
We have already downloaded this sample and stored it in the directory `resources/vibrio_genomes`, along with 62 other complete genomes collected since 2019, also downloaded from the [NCBI website](https://www.ncbi.nlm.nih.gov/datasets/genome/?taxon=666&annotated_only=true&refseq_annotation=true&typical_only=true&assembly_level=3%3A3&release_year=2019%3A2023). 
We will later use these genomes for our phylogenetic analysis. 

We can check all our genomes with the `ls` command: 

```bash
ls resources/vibrio_genomes
```

```
GCF_004117115.1_ASM411711v1_genomic.fna   GCF_013085165.1_ASM1308516v1_genomic.fna  GCF_019458445.1_ASM1945844v1_genomic.fna
GCF_004328575.1_ASM432857v1_genomic.fna   GCF_013357605.1_ASM1335760v1_genomic.fna  GCF_019458465.1_ASM1945846v1_genomic.fna
GCF_008369605.1_ASM836960v1_genomic.fna   GCF_013357625.1_ASM1335762v1_genomic.fna  GCF_019504425.1_ASM1950442v1_genomic.fna
GCF_009646135.1_ASM964613v1_genomic.fna   GCF_013357645.1_ASM1335764v1_genomic.fna  GCF_019704175.1_ASM1970417v1_genomic.fna

... etc ...
```

## Summary

::: {.callout-tip}
#### Key Points

- TODO
:::
